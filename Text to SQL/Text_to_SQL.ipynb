{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## **Creating SQL Queries from Natural Language**\n",
        "\n",
        "This tutorial will guide you through creating an application that generates SQL queries from natural language instructions and evaluates the quality of the generated queries. Along the way, you'll learn how to use Orq's deployment feature to enhance SQL generation. By the end of this tutorial, you'll be ready to experiment with SQL generation in your own projects.\n",
        "\n",
        "Before starting, ensure you have an Orq account. If not, sign up at Orq.ai. Let's dive in!\n",
        "\n",
        "**Step 1: Setting Up the Environment**  \n",
        "The following commands install the required libraries for working with the Orq platform, handling datasets, and managing the SQL generation workflow."
      ],
      "metadata": {
        "id": "-xkOTicqv3UN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import packages"
      ],
      "metadata": {
        "id": "m5wV0m-2pJXK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0fvzfasCrjMP"
      },
      "outputs": [],
      "source": [
        "!pip install orq-ai-sdk datasets huggingface_hub"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Initializing the OrqAI Client\n",
        "\n",
        "This code initializes the OrqAI client with an API key, either from the `ORQ_API_KEY` environment variable or a hardcoded default, and sets the environment to production."
      ],
      "metadata": {
        "id": "2376eP5Wva7h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from orq_ai_sdk import Orq\n",
        "\n",
        "client = Orq(\n",
        "  api_key=os.environ.get(\"ORQ_API_KEY\", \"YOUR_ORQ_API\"),\n",
        ")"
      ],
      "metadata": {
        "id": "P_CQXzMhwMaR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Hugging Face**\n",
        "\n",
        "Before proceeding, sign up for a free Hugging Face account if you don't already have one. You'll need an API key to access their datasets library. Retrieve your API key [here](https://huggingface.co/settings/tokens) after signing up or logging in.\n",
        "\n",
        "**Step 3: Loading the Dataset**  \n",
        "Use the Hugging Face datasets library to load a dataset containing table schemas and natural language instructions. Convert the dataset to a pandas DataFrame for easy manipulation."
      ],
      "metadata": {
        "id": "KF6e3ZquwEwX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import login\n",
        "\n",
        "# Use your Hugging Face API token\n",
        "login(token=\"YOUR_HUGGING_FACE_API\")"
      ],
      "metadata": {
        "id": "zZhWiMh-r3N-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "ds = load_dataset(\"Clinton/Text-to-sql-v1\")\n",
        "\n",
        "# Convert to a pandas DataFrame (selecting the \"train\" split as an example)\n",
        "df = ds[\"train\"].to_pandas()\n",
        "\n",
        "# Select the top 50 rows\n",
        "df = df.head(50)\n",
        "\n",
        "# Display the DataFrame\n",
        "print(df)"
      ],
      "metadata": {
        "id": "bVtu2PVqsS7b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "id": "BmFSQ57bt_9T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **SQL Query Generation Use Case**\n",
        "This deployment is designed to generate valid SQL queries based on specific table schemas and user-provided instructions. The model analyzes the instruction and the associated table schema to produce a precise and contextually appropriate SQL query.\n",
        "\n",
        "SQL query generation is particularly useful when automating database interactions, building query assistants, or streamlining the process of accessing structured data through natural language inputs."
      ],
      "metadata": {
        "id": "EJ5-MLEjmpg9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = df[[\"instruction\", \"input\", \"response\"]]"
      ],
      "metadata": {
        "id": "Fou7FuiY-Wgk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 4: Generating SQL Queries**\n",
        "\n",
        "This step involves invoking the Orq deployment to generate SQL queries for each row in the dataset. The instruction column provides the natural language task, while the input column contains the table schema. The results are stored in a new column named output."
      ],
      "metadata": {
        "id": "j6XQIr2lxbgK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the outputs list\n",
        "outputs = []\n",
        "\n",
        "# Iterate through each row in the DataFrame\n",
        "for _, row in df.iterrows():\n",
        "    # Extract the 'instruction' and 'input' columns for each row\n",
        "    instruction = row[\"instruction\"]\n",
        "    table = row[\"input\"]\n",
        "\n",
        "    # Invoke the deployment for each row\n",
        "    generation = client.deployments.invoke(\n",
        "        key=\"text_to_SQL\",  # Replace with your actual deployment key\n",
        "        context={\n",
        "            \"environments\": []\n",
        "        },\n",
        "        inputs={\n",
        "            \"table\": table,\n",
        "            \"instruction\": instruction\n",
        "        },\n",
        "        metadata={\n",
        "            \"custom-field-name\": \"custom-metadata-value\"\n",
        "        }\n",
        "    )\n",
        "\n",
        "    # Append the model's output to the outputs list\n",
        "    outputs.append(generation.choices[0].message.content)\n",
        "\n",
        "# Add the outputs as a new column in the DataFrame\n",
        "df[\"output\"] = outputs"
      ],
      "metadata": {
        "id": "RbU_GUtXvgc6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Performance Check"
      ],
      "metadata": {
        "id": "ILiNBC2GzMJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 5: Saving and Evaluating Results**  \n",
        "Save the updated DataFrame containing the SQL queries to a file and evaluate their quality. Use metrics or manual inspection to verify the accuracy and relevance of the generated queries."
      ],
      "metadata": {
        "id": "kYL28tX8xl6S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "5_Q3tNsV_Q5f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score\n",
        "\n",
        "true_labels = df[\"response\"]\n",
        "predicted_labels = df[\"output\"]\n",
        "\n",
        "# Calculate performance metrics\n",
        "accuracy = accuracy_score(true_labels, predicted_labels)\n",
        "precision = precision_score(true_labels, predicted_labels, average='macro', zero_division=0)\n",
        "recall = recall_score(true_labels, predicted_labels, average='macro', zero_division=0)\n",
        "f1 = f1_score(true_labels, predicted_labels, average='macro', zero_division=0)\n",
        "\n",
        "# Print the metrics\n",
        "print(\"Performance Metrics:\")\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")"
      ],
      "metadata": {
        "id": "tiFlI11-wk-V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Next Steps**  \n",
        "Congratulations! You've successfully built and tested a SQL generation application using Orq. To further enhance your project:\n",
        "\n",
        "- Experiment with different datasets or deployment keys.\n",
        "- Refine the prompt to improve SQL generation quality.\n",
        "- Integrate the solution into a larger application for automated data access.\n",
        "\n",
        "For more details and advanced features, visit the Orq documentation."
      ],
      "metadata": {
        "id": "RgCW2oASxr3A"
      }
    }
  ]
}
