{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deployment Metrics\n",
    "\n",
    "## Overview\n",
    "\n",
    "### Available Operations\n",
    "\n",
    "* [create](#Create) - Add metrics to a deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup\n",
    "\n",
    "Before trying out the code set up the virtual environment and the environment variable. \n",
    "\n",
    "On the terminal go to the project directory, activate the virtual environment and install Orq sdk:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  pip install orq-ai-sdk - latest version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next set up the API key:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"ORQ_API_KEY\"] = \"\" # Your Api key here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from orq_ai_sdk import Orq\n",
    "import os\n",
    "\n",
    "orq = Orq(server_url=\"https://my.staging.orq.ai\", api_key=os.getenv(\"ORQ_API_KEY\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create\n",
    "\n",
    "Add metrics to deployments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "deployment_key = \"Prompt_Test_Updated_4spi_42\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "object='list' data=[Data(id='05a5963b-3bcf-442e-8157-4e7431f85c40', created='2025-02-18T09:47:43.985Z', updated='2025-02-24T11:20:40.245Z', key='Prompt_Test_Updated_4spi_42', description='', prompt_config=DeploymentsPromptConfig(tools=[], model='claude-3-5-haiku-20241022', model_type='chat', model_parameters=DeploymentsModelParameters(temperature=0.7, max_tokens=200.0, top_k=5.0, top_p=0.7, frequency_penalty=None, presence_penalty=None, num_images=None, seed=None, format_=None, dimensions=None, quality=None, style=None, response_format=Unset(), photo_real_version=None, encoding_format=None, reasoning_effort=None), provider='anthropic', messages=[DeploymentsMessages(role='system', content='You are a helpful assistant. Test', tool_calls=None), DeploymentsMessages(role='assistant', content='you will help me answer all the quesitons in a concise and clear manner', tool_calls=None)]), version='1.2'), Data(id='1a39f268-7187-460a-9e95-03b6a093cfbc', created='2025-02-11T08:51:23.888Z', updated='2025-02-17T15:04:30.562Z', key='Azure', description='', prompt_config=DeploymentsPromptConfig(tools=[], model='gpt-35-turbo', model_type='chat', model_parameters=DeploymentsModelParameters(temperature=0.2, max_tokens=256.0, top_k=None, top_p=0.0, frequency_penalty=0.0, presence_penalty=0.0, num_images=None, seed=None, format_=None, dimensions=None, quality=None, style=None, response_format=Unset(), photo_real_version=None, encoding_format=None, reasoning_effort=None), provider='azure', messages=[DeploymentsMessages(role='user', content='You are a helpful assistant.', tool_calls=None)]), version='1.0'), Data(id='547eba80-99d2-4ffa-b897-e4b7cdd07f9a', created='2025-02-11T08:51:23.888Z', updated='2025-02-18T15:45:04.442Z', key='Groq', description='', prompt_config=DeploymentsPromptConfig(tools=[], model='llama2-70b-4096', model_type='chat', model_parameters=DeploymentsModelParameters(temperature=0.2, max_tokens=256.0, top_k=None, top_p=0.0, frequency_penalty=None, presence_penalty=None, num_images=None, seed=None, format_=None, dimensions=None, quality=None, style=None, response_format=Unset(), photo_real_version=None, encoding_format=None, reasoning_effort=None), provider='groq', messages=[DeploymentsMessages(role='user', content='You are a helpful assistant.', tool_calls=None)]), version='1.0'), Data(id='63be10d7-2523-4084-b9e5-8cc10ce8fc48', created='2025-02-11T08:51:23.888Z', updated='2025-02-18T15:45:13.168Z', key='OpenAI', description='', prompt_config=DeploymentsPromptConfig(tools=[], model='gpt-3.5-turbo', model_type='chat', model_parameters=DeploymentsModelParameters(temperature=0.2, max_tokens=256.0, top_k=None, top_p=0.0, frequency_penalty=0.0, presence_penalty=0.0, num_images=None, seed=None, format_=None, dimensions=None, quality=None, style=None, response_format=Unset(), photo_real_version=None, encoding_format=None, reasoning_effort=None), provider='openai', messages=[DeploymentsMessages(role='user', content='You are a helpful assistant.', tool_calls=None)]), version='1.0'), Data(id='a59dcee5-bd1a-45f9-8899-0358b6bad214', created='2025-02-11T12:58:38.395Z', updated='2025-02-11T14:02:54.907Z', key='testing_66_gvto_37', description='', prompt_config=DeploymentsPromptConfig(tools=[], model='gpt-4o', model_type='vision', model_parameters=DeploymentsModelParameters(temperature=0.2, max_tokens=256.0, top_k=None, top_p=0.7, frequency_penalty=0.0, presence_penalty=0.0, num_images=None, seed=None, format_=None, dimensions=None, quality=None, style=None, response_format=Unset(), photo_real_version=None, encoding_format=None, reasoning_effort=None), provider='azure', messages=[DeploymentsMessages(role='system', content='You are a helpful assistant.', tool_calls=None), DeploymentsMessages(role='user', content='what is your name?', tool_calls=None), DeploymentsMessages(role='assistant', content='give me an answer', tool_calls=None)]), version='1.2'), Data(id='bfbd227e-208b-4c85-af5d-ad5164a53226', created='2025-02-11T08:51:23.888Z', updated='2025-02-11T12:45:40.133Z', key='Perplexity', description='', prompt_config=DeploymentsPromptConfig(tools=[], model='llama-2-70b-chat', model_type='chat', model_parameters=DeploymentsModelParameters(temperature=0.2, max_tokens=256.0, top_k=50.0, top_p=0.0, frequency_penalty=0.0, presence_penalty=0.0, num_images=None, seed=None, format_=None, dimensions=None, quality=None, style=None, response_format=Unset(), photo_real_version=None, encoding_format=None, reasoning_effort=None), provider='perplexity', messages=[DeploymentsMessages(role='user', content='You are a helpful assistant.', tool_calls=None)]), version='1.0'), Data(id='fe8a32a1-2455-49bd-9f30-b0ec62b8fccc', created='2025-02-11T11:11:10.384Z', updated='2025-02-11T14:47:04.789Z', key='t_66', description='this is my testing deployment', prompt_config=DeploymentsPromptConfig(tools=[], model='gpt-35-turbo', model_type='chat', model_parameters=DeploymentsModelParameters(temperature=0.2, max_tokens=256.0, top_k=None, top_p=0.1, frequency_penalty=0.0, presence_penalty=0.0, num_images=None, seed=None, format_=None, dimensions=None, quality=None, style=None, response_format=Unset(), photo_real_version=None, encoding_format=None, reasoning_effort=None), provider='azure', messages=[DeploymentsMessages(role='system', content='You are a helpful assistant.', tool_calls=None), DeploymentsMessages(role='user', content='hi what is your name?', tool_calls=None)]), version='1.1')] has_more=False\n",
      "Help on method create in module orq_ai_sdk.metrics:\n",
      "\n",
      "create(*, id: str, metadata: Optional[Dict[str, Any]] = None, usage: Union[orq_ai_sdk.models.deploymentcreatemetricop.Usage, orq_ai_sdk.models.deploymentcreatemetricop.UsageTypedDict, NoneType] = None, performance: Union[orq_ai_sdk.models.deploymentcreatemetricop.Performance, orq_ai_sdk.models.deploymentcreatemetricop.PerformanceTypedDict, NoneType] = None, messages: Union[List[orq_ai_sdk.models.deploymentcreatemetricop.DeploymentCreateMetricMessages], List[orq_ai_sdk.models.deploymentcreatemetricop.DeploymentCreateMetricMessagesTypedDict], NoneType] = None, choices: Union[List[orq_ai_sdk.models.deploymentcreatemetricop.Choices], List[orq_ai_sdk.models.deploymentcreatemetricop.ChoicesTypedDict], NoneType] = None, feedback: Union[orq_ai_sdk.models.deploymentcreatemetricop.DeploymentCreateMetricFeedback, orq_ai_sdk.models.deploymentcreatemetricop.DeploymentCreateMetricFeedbackTypedDict, NoneType] = None, retries: OptionalNullable[orq_ai_sdk.utils.retries.RetryConfig] = Unset(), server_url: Optional[str] = None, timeout_ms: Optional[int] = None, http_headers: Optional[Mapping[str, str]] = None) -> Optional[orq_ai_sdk.models.deploymentcreatemetricop.DeploymentCreateMetricResponseBody] method of orq_ai_sdk.metrics.Metrics instance\n",
      "    Add metrics\n",
      "\n",
      "    Add metrics to a deployment\n",
      "\n",
      "    :param id: Deployment ID\n",
      "    :param metadata: Your own custom key-value pairs can be attached to the logs. This is useful for storing additional information related to your interactions with the LLM providers or specifics within your application.\n",
      "    :param usage: Usage statistics to add to the deployment\n",
      "    :param performance:\n",
      "    :param messages: A list of messages sent to the model.\n",
      "    :param choices: A list of completion choices. If you are using a `completion` model then you must provide the `completion content` with the chat completion format\n",
      "    :param feedback: Feedback from the user on the completion\n",
      "    :param retries: Override the default retry configuration for this method\n",
      "    :param server_url: Override the default server URL for this method\n",
      "    :param timeout_ms: Override the default request timeout configuration for this method in milliseconds\n",
      "    :param http_headers: Additional headers to set or replace on requests.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# just to check the id of the deployment\n",
    "res = orq.deployments.list()\n",
    "print(res)\n",
    "#------------------------------------------------\n",
    "\n",
    "help(orq.deployments.metrics.create) # if it is trace id then that should be changed in the \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The invoked output is:  id='01JMW2BX0JBVXN6VNH1R85NJ3N' created=datetime.datetime(2025, 2, 24, 13, 29, 26, 303000, tzinfo=TzInfo(UTC)) object='chat' model='claude-3-5-haiku-20241022' provider='anthropic' is_final=True choices=[DeploymentInvokeChoices(index=0.0, message=DeploymentInvokeMessage1(role='assistant', tool_calls=[], content='.'), finish_reason='end_turn')] integration_id=None finalized=datetime.datetime(2025, 2, 24, 13, 29, 26, 795000, tzinfo=TzInfo(UTC)) system_fingerprint=Unset() retrievals=None provider_response={'id': 'msg_01Xd8umeHGvwuHFchLNmgB6Z', 'type': 'message', 'role': 'assistant', 'model': 'claude-3-5-haiku-20241022', 'content': [{'type': 'text', 'text': '.'}], 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 40, 'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0, 'output_tokens': 4}}\n"
     ]
    },
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for Unmarshaller\nbody.code\n  Field required [type=missing, input_value={'success': True}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.10/v/missing",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[60], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe invoked output is: \u001b[39m\u001b[38;5;124m\"\u001b[39m, res)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# to add the metrics\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43morq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdeployments\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mid\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m01JMW2AQWSJEGQTAME26EH2GZ2\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m res \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Handle response\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\aryan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\orq_ai_sdk\\metrics.py:134\u001b[0m, in \u001b[0;36mMetrics.create\u001b[1;34m(self, id, metadata, usage, performance, messages, choices, feedback, retries, server_url, timeout_ms, http_headers)\u001b[0m\n\u001b[0;32m    119\u001b[0m http_res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdo_request(\n\u001b[0;32m    120\u001b[0m     hook_ctx\u001b[38;5;241m=\u001b[39mHookContext(\n\u001b[0;32m    121\u001b[0m         base_url\u001b[38;5;241m=\u001b[39mbase_url \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    130\u001b[0m     retry_config\u001b[38;5;241m=\u001b[39mretry_config,\n\u001b[0;32m    131\u001b[0m )\n\u001b[0;32m    133\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m utils\u001b[38;5;241m.\u001b[39mmatch_response(http_res, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m200\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapplication/json\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 134\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munmarshal_json\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    135\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhttp_res\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mOptional\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDeploymentCreateMetricResponseBody\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m    136\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    137\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m utils\u001b[38;5;241m.\u001b[39mmatch_response(http_res, [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m400\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m401\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m4XX\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    138\u001b[0m     http_res_text \u001b[38;5;241m=\u001b[39m utils\u001b[38;5;241m.\u001b[39mstream_to_text(http_res)\n",
      "File \u001b[1;32mc:\\Users\\aryan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\orq_ai_sdk\\utils\\serializers.py:133\u001b[0m, in \u001b[0;36munmarshal_json\u001b[1;34m(raw, typ)\u001b[0m\n\u001b[0;32m    132\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21munmarshal_json\u001b[39m(raw, typ: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m--> 133\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43munmarshal\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfrom_json\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\aryan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\orq_ai_sdk\\utils\\serializers.py:143\u001b[0m, in \u001b[0;36munmarshal\u001b[1;34m(val, typ)\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21munmarshal\u001b[39m(val, typ: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    137\u001b[0m     unmarshaller \u001b[38;5;241m=\u001b[39m create_model(\n\u001b[0;32m    138\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnmarshaller\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    139\u001b[0m         body\u001b[38;5;241m=\u001b[39m(typ, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m),\n\u001b[0;32m    140\u001b[0m         __config__\u001b[38;5;241m=\u001b[39mConfigDict(populate_by_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, arbitrary_types_allowed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[0;32m    141\u001b[0m     )\n\u001b[1;32m--> 143\u001b[0m     m \u001b[38;5;241m=\u001b[39m \u001b[43munmarshaller\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    145\u001b[0m     \u001b[38;5;66;03m# pyright: ignore[reportAttributeAccessIssue]\u001b[39;00m\n\u001b[0;32m    146\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m m\u001b[38;5;241m.\u001b[39mbody\n",
      "File \u001b[1;32mc:\\Users\\aryan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pydantic\\main.py:214\u001b[0m, in \u001b[0;36mBaseModel.__init__\u001b[1;34m(self, **data)\u001b[0m\n\u001b[0;32m    212\u001b[0m \u001b[38;5;66;03m# `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\u001b[39;00m\n\u001b[0;32m    213\u001b[0m __tracebackhide__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 214\u001b[0m validated_self \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__pydantic_validator__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mself_instance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m validated_self:\n\u001b[0;32m    216\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    217\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA custom validator is returning a value other than `self`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    218\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReturning anything other than `self` from a top level model validator isn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt supported when validating via `__init__`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    219\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSee the `model_validator` docs (https://docs.pydantic.dev/latest/concepts/validators/#model-validators) for more details.\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    220\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[0;32m    221\u001b[0m     )\n",
      "\u001b[1;31mValidationError\u001b[0m: 1 validation error for Unmarshaller\nbody.code\n  Field required [type=missing, input_value={'success': True}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.10/v/missing"
     ]
    }
   ],
   "source": [
    "trace_id = \"01JMVVDEQ13Y91A58FKNB8F6FG\"\n",
    "\n",
    "res = orq.deployments.invoke(key = 'Prompt_Test_Updated_4spi_42')\n",
    "\n",
    "print(\"The invoked output is: \", res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'success': True}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "resp = requests.post(\n",
    "    \"https://my.staging.orq.ai/v2/deployments/01JMVVDEQ13Y91A58FKNB8F6FG/metrics\",\n",
    "    headers={\"Authorization\": \"Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ3b3Jrc3BhY2VJZCI6IjY4YWI5NTgwLTEyNjAtNDlhMS04MjY4LWZjNTJlMTM1NGJlMSIsImlzcyI6Im9ycSIsImlhdCI6MTc0MDM4NTA0M30.xyvnUerNIgLRxHxbNvEd3-BWjkRsg-LA5ta--Cfjoeg \"},  # if needed\n",
    "    json={\"id\":\"01JMW2AQWSJEGQTAME26EH2GZ2\"}\n",
    ")\n",
    "\n",
    "print(resp.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 validation error for Unmarshaller\n",
      "body.code\n",
      "  Field required [type=missing, input_value={'success': True}, input_type=dict]\n",
      "    For further information visit https://errors.pydantic.dev/2.10/v/missing\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "  res = orq.deployments.metrics.create(id=\"01JMW2AQWSJEGQTAME26EH2GZ2\")\n",
    "except Exception as e:\n",
    "  print(e)\n",
    "\n",
    "assert res is not None\n",
    "\n",
    "# Handle response\n",
    "# print(res)\n",
    "#even with the trace id it is not working and the same error is returned\n",
    "\n",
    "## postman returns success = true and 200OK"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
