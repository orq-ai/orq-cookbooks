{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m5wV0m-2pJXK"
      },
      "source": [
        "\n",
        "## **Intent Classification with Orq.ai**\n",
        "\n",
        "**Prerequisites**\n",
        "\n",
        "In this tutorial we will use Orq.ai and Hugging Face secret API keys. Before you get started: find [Orq.ai API key](https://docs.orq.ai/docs/administer/api-keys) and [Hugging Face API key](https://huggingface.co/docs/hub/en/security-tokens) first. In Google Colab You can [safely store your API secret keys](https://www.youtube.com/watch?v=LPa51KxqUAw) by clicking the Key icon on the left and setting up the variables\n",
        "\n",
        "Those are the variables that you need to set:\n",
        "\n",
        "*   ```YOUR_HUGGING_FACE_API```: your API here\n",
        "*   ```YOUR_ORQ_API_KEY```: your API here\n",
        "\n",
        "\n",
        "load the API keys:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lzIy87WibSzY"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "\n",
        "# Use your Hugging Face API token\n",
        "YOUR_HUGGING_FACE_API = userdata.get(\"YOUR_HUGGING_FACE_API\")\n",
        "YOUR_ORQ_API = userdata.get(\"YOUR_ORQ_API_KEY\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EZwakoCOcYeB"
      },
      "source": [
        "\n",
        "\n",
        "**Step 1: Install Dependencies**  \n",
        "Start by installing the required packages. These include the Orq SDK and additional libraries for handling datasets and managing environment variables."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0fvzfasCrjMP"
      },
      "outputs": [],
      "source": [
        "!pip install orq-ai-sdk datasets huggingface_hub"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2376eP5Wva7h"
      },
      "source": [
        "**Step 2: Initialize the Orq Client**  \n",
        "\n",
        "The Orq client allows you to communicate with the Orq platform. Set it up using your API key, which can be stored as an environment variable (ORQ_API_KEY) or passed directly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P_CQXzMhwMaR"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "from orq_ai_sdk import Orq\n",
        "\n",
        "client = Orq(\n",
        "  api_key=YOUR_ORQ_API,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KF6e3ZquwEwX"
      },
      "source": [
        "### **Hugging Face**\n",
        "\n",
        "Before proceeding, sign up for a free Hugging Face account if you don't already have one. You'll need an API key to access their datasets library. Retrieve your API key here after signing up or logging in.\n",
        "\n",
        "**Step 3: Load a Dataset**  \n",
        "Use the Hugging Face datasets library to load the dataset for intent classification. Here, we use a public dataset that contains user queries labeled with intents."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zZhWiMh-r3N-"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import login\n",
        "\n",
        "login(token=YOUR_HUGGING_FACE_API)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4vvuKLupYOzy"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "# Load dataset\n",
        "dataset = load_dataset(\"Bhuvaneshwari/intent_classification\")\n",
        "df = dataset[\"train\"].to_pandas()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bVtu2PVqsS7b"
      },
      "outputs": [],
      "source": [
        "# Select the top 50 rows\n",
        "df = df.head(50)\n",
        "\n",
        "# Display the DataFrame\n",
        "print(df)\n",
        "\n",
        "# Optional: Check the shape and columns\n",
        "print(f\"\\nShape: {df.shape}\")\n",
        "print(f\"\\nColumns: {df.columns.tolist()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BmFSQ57bt_9T"
      },
      "outputs": [],
      "source": [
        "# Extract unique labels from the \"intent\" column\n",
        "unique_labels = df[\"intent\"].unique()\n",
        "unique_labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EJ5-MLEjmpg9"
      },
      "source": [
        "### **Adding Generated Responses to DataFrame**\n",
        "\n",
        "This code adds an empty column to the DataFrame for storing generated responses, iterates through each row to generate a response based on the `text_input`, and then saves the updated DataFrame.\n",
        "\n",
        "#### **Intent classification prompt**\n",
        "\n",
        "This deployment is designed to classify user inputs into specific intents to understand the purpose behind their requests. The model will identify the most appropriate intent from a predefined set, enabling precise and context-aware responses.\n",
        "\n",
        "Intent recognition is particularly useful when setting up chatbots\n",
        "\n",
        "This is the prompt in Orq.ai:\n",
        "\n",
        "```plaintext\n",
        "You are tasked with identifying the intent behind user inputs based on the following intents:\n",
        "'PlayMusic', 'AddToPlaylist', 'RateBook', 'Greetings', 'SearchScreeningEvent', 'BookRestaurant', 'GetWeather', 'Book Meeting', 'SearchCreativeWork', 'Cancellation', 'Affirmation', 'excitment'.\n",
        "\n",
        "Here are some examples:\n",
        "\n",
        "Input: \"Hey there, how are you doing?\"\n",
        "Intent: Greetings\n",
        "\n",
        "Input: \"Play the album Abbey Road by The Beatles.\"\n",
        "Intent: PlayMusic\n",
        "\n",
        "Input: \"Add this song to my workout playlist.\"\n",
        "Intent: AddToPlaylist\n",
        "\n",
        "Input: \"This book deserves a solid five-star rating.\"\n",
        "Intent: RateBook\n",
        "\n",
        "ONLY OUTPUT THE LABEL WITHOUT ''\n",
        "\n",
        "here is the input that needs intent classification: {{text}}\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZZDsqLBI1hnG"
      },
      "source": [
        "**Step 4: Invoke Orq Deployment**  \n",
        "\n",
        "Integrate the Orq intent classification model by invoking a deployed model for predictions. Iterate through the dataset and store the results in a new column called \"output\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RbU_GUtXvgc6"
      },
      "outputs": [],
      "source": [
        "# Placeholder for the deployment key\n",
        "deployment_key = \"intent_classification\"\n",
        "\n",
        "# Create an empty list to store outputs\n",
        "outputs = []\n",
        "\n",
        "# Iterate through the rows of the DataFrame\n",
        "for index, row in df.iterrows():\n",
        "    text_input = row[\"text\"]  # Extract the text column\n",
        "\n",
        "    # Invoke the model for each text input\n",
        "    generation = client.deployments.invoke(\n",
        "        key=deployment_key,\n",
        "        context={\n",
        "            \"environments\": []\n",
        "        },\n",
        "        inputs={\n",
        "            \"text\": text_input\n",
        "        },\n",
        "        metadata={\n",
        "            \"custom-field-name\": \"custom-metadata-value\"\n",
        "        }\n",
        "    )\n",
        "\n",
        "    # Append the output to the list\n",
        "    outputs.append(generation.choices[0].message.content)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8q1d5XIyyWrM"
      },
      "outputs": [],
      "source": [
        " # Add the output column to the DataFrame\n",
        "df[\"output\"] = outputs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ILiNBC2GzMJ3"
      },
      "source": [
        "**Step 5: Evaluate Model Performance**  \n",
        "\n",
        "Use metrics such as accuracy, precision, recall, and F1-score to assess the quality of your model's predictions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tiFlI11-wk-V"
      },
      "outputs": [],
      "source": [
        "\n",
        "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score\n",
        "\n",
        "true_labels = df[\"intent\"]\n",
        "predicted_labels = df[\"output\"]\n",
        "\n",
        "# Calculate performance metrics\n",
        "accuracy = accuracy_score(true_labels, predicted_labels)\n",
        "precision = precision_score(true_labels, predicted_labels, average='macro')\n",
        "recall = recall_score(true_labels, predicted_labels, average='macro')\n",
        "f1 = f1_score(true_labels, predicted_labels, average='macro')\n",
        "\n",
        "# Print the metrics\n",
        "print(\"Performance Metrics:\")\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "05oi1aSt1uPu"
      },
      "source": [
        "**Next Steps**  \n",
        "\n",
        "Congratulations! You've successfully built and evaluated an intent classification application using Orq. To further enhance your application:\n",
        "\n",
        "- Explore other datasets and use cases.\n",
        "- Integrate the model into a chatbot or voice assistant.\n",
        "- Automate deployment and testing with Orq's advanced features.\n",
        "\n",
        "For more resources, visit the Orq documentation."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
