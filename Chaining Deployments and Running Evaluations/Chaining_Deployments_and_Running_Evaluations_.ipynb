{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## **Image-Based Receipt Extraction with Orq**\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "In this cookbook, we chain two deployments to process financial data from image files, to create a workflow. First, we perform data extraction on a JPG file, converting unstructured receipt information into structured JSON. We then run an evaluator to verify that the output is valid JSON and check whether the tax amount has been correctly extracted. Next, the validated financial data is passed to a second deployment that summarizes the extracted information, providing clear, actionable insights.\n",
        "\n",
        "Separating these tasks improves accuracy by allowing each step to be optimized independently, and it enables granular checking at each stage. This ensures better validation, making it easier to diagnose errors and refine the process. By leveraging Orq’s capabilities, this workflow delivers a scalable and efficient approach to processing image-based receipts.\n",
        "\n",
        "To make things even easier, we’ve created this [Google Colab file](https://colab.research.google.com/drive/1omYqGjiED1K2Hd-g7oXUzU92kwcL_7Lt#scrollTo=nPskNRdFyeTK) that you can copy and run straight away after replacing the API key—the deployment is already live and ready in the deployment section. Below, we’ll run through the code step by step for further explanation.\n",
        "\n",
        "Ready to unlock Orq's magic?[ Sign up](https://orq.ai/create-account) to get started and keep the process rolling!\n",
        "\n",
        "**Step 1: Preparing the Environment**  \n",
        "Before diving into image processing, the necessary tools must be in place. Installing the Orq SDK is quick and straightforward, setting the stage for seamless integration."
      ],
      "metadata": {
        "id": "nPskNRdFyeTK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install orq-ai-sdk\n",
        "\n",
        "#import\n",
        "import pandas as pd\n",
        "from google.colab import auth"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FaqaxBLgv98I",
        "outputId": "4d6aaa0d-9f54-4ce5-a0c6-b56ae62f2469"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting orq-ai-sdk\n",
            "  Downloading orq_ai_sdk-3.14.8-py3-none-any.whl.metadata (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.2/41.2 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: httpcore>=1.0.9 in /usr/local/lib/python3.12/dist-packages (from orq-ai-sdk) (1.0.9)\n",
            "Requirement already satisfied: httpx>=0.28.1 in /usr/local/lib/python3.12/dist-packages (from orq-ai-sdk) (0.28.1)\n",
            "Requirement already satisfied: pydantic>=2.11.2 in /usr/local/lib/python3.12/dist-packages (from orq-ai-sdk) (2.11.10)\n",
            "Requirement already satisfied: requests==2.32.4 in /usr/local/lib/python3.12/dist-packages (from orq-ai-sdk) (2.32.4)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests==2.32.4->orq-ai-sdk) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests==2.32.4->orq-ai-sdk) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests==2.32.4->orq-ai-sdk) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests==2.32.4->orq-ai-sdk) (2025.10.5)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore>=1.0.9->orq-ai-sdk) (0.16.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx>=0.28.1->orq-ai-sdk) (4.11.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.11.2->orq-ai-sdk) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.11.2->orq-ai-sdk) (2.33.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.11.2->orq-ai-sdk) (4.15.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.11.2->orq-ai-sdk) (0.4.2)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx>=0.28.1->orq-ai-sdk) (1.3.1)\n",
            "Downloading orq_ai_sdk-3.14.8-py3-none-any.whl (428 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m428.2/428.2 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: orq-ai-sdk\n",
            "Successfully installed orq-ai-sdk-3.14.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "With the SDK installed, the focus shifts to setting up the client and preparing the workflow.\n",
        "\n",
        "**Step 2: Setting Up the Orq Client**  \n",
        "The Orq client bridges your environment with Orq’s powerful APIs. By authenticating with an API key, it provides access to deployments that simplify data extraction from images.\n",
        "\n",
        "After you are logged into the platform, you can find your API key [here](https://my.orq.ai/orquesta-demos/settings/developers)."
      ],
      "metadata": {
        "id": "B2c-o6VtyncP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "from orq_ai_sdk import Orq\n",
        "\n",
        "client = Orq(\n",
        "  api_key=os.environ.get(\"ORQ_API_KEY\", \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ3b3Jrc3BhY2VJZCI6Ijg5NTYwYTU4LTJmN2YtNDJiYS1hMjJhLTFiZmE3MDA4NjZhZSIsImlzcyI6Im9ycSIsImlhdCI6MTc2MDM0NzUyNn0.1ADOy9IV9sIUPl9dr6fxGBUU1kDdoef8T1vfI-uhQr8\"),\n",
        ")"
      ],
      "metadata": {
        "id": "C_Dn6BO9yVkI"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once connected, the client is ready to process image files for extraction.\n",
        "\n",
        "**Step 3: Converting Images to Base64**  \n",
        "To process images with Orq’s deployments, they must first be encoded into Base64 format. This section outlines how to process a folder of .jpg and .png files, preparing them for data extraction.\n",
        "\n",
        "To get you started, we’ve provided a Google Drive folder filled with .jpg files of receipts that you can copy and use to test and explore the workflow."
      ],
      "metadata": {
        "id": "aJtts4g7mvus"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import base64\n",
        "\n",
        "# Specify the folder containing image files\n",
        "folder_path = '/content/drive/MyDrive/receipts_test'\n",
        "\n",
        "# Get all .jpg and .png files from the folder\n",
        "image_files = [file for file in os.listdir(folder_path) if file.endswith(('.jpg', '.png'))]\n",
        "\n",
        "# List to store Base64-encoded data for each image\n",
        "base64_images = []\n",
        "\n",
        "# Iterate through image files and convert them to Base64\n",
        "for image_file in image_files:\n",
        "    file_path = os.path.join(folder_path, image_file)\n",
        "    try:\n",
        "        with open(file_path, 'rb') as img_file:\n",
        "            # Encode the image to Base64\n",
        "            base64_data = base64.b64encode(img_file.read()).decode('utf-8')\n",
        "            base64_images.append(base64_data)\n",
        "            print(f\"Encoded {image_file} to Base64.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {image_file}: {e}\")\n",
        "\n",
        "# Output the Base64-encoded data for each image\n",
        "print(\"Base64-encoded images ready for processing.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "id": "_6LDA0Rvm3M1",
        "outputId": "4cf4f818-e19c-4b40-f2c7-49ee695d759a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/drive/MyDrive/receipts_test'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-733780985.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Get all .jpg and .png files from the folder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mimage_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfile\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder_path\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.jpg'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# List to store Base64-encoded data for each image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/receipts_test'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 5: Data Extraction Deployment**\n",
        "\n",
        "With images in Base64 format, the final step is to send each encoded image to Orq’s DataExtraction_Receipts deployment. We store the extracted information in a list so it can be passed to the next deployment.\n",
        "\n",
        "#### **Prompt**\n",
        "To achieve accurate extraction, we use a well-defined prompt that provides clear instructions on identifying key financial details. It specifies exactly what information should be extracted—transaction date, vendor name, amounts (total, pre-tax, and tax), and payment details. By explicitly requesting tax type differentiation and category classification, the prompt ensures a granular and precise extraction.\n",
        "\n",
        "#### **Tools**\n",
        "To keep things structured, we use a JSON schema as our data blueprint. This schema acts as a quality control tool, ensuring that all extracted fields are correctly formatted and validated. Beyond just verification, this structured output makes the data programmatically accessible, allowing seamless integration into other systems, automated workflows, or financial analyses—without the need for manual intervention."
      ],
      "metadata": {
        "id": "vPeOCFi3y1CC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "# Initialize an empty list to store extraction results\n",
        "extraction_results = []\n",
        "\n",
        "# Iterate through each Base64-encoded image and invoke the deployment\n",
        "for base64_image in base64_images:\n",
        "    try:\n",
        "        # Construct the invocation payload\n",
        "        generation = client.deployments.invoke(\n",
        "            key=\"data_extraction_receipt_or_invoice\",\n",
        "            messages=[\n",
        "                {\n",
        "                    \"role\": \"user\",\n",
        "                    \"content\": [\n",
        "                        {\"text\": \"Extract what is on the receipt\", \"type\": \"text\"},\n",
        "                        {\n",
        "                            \"type\": \"image_url\",\n",
        "                            \"image_url\": {\n",
        "                                \"url\": \"data:image/png;base64,\" + base64_image\n",
        "                            },\n",
        "                        },\n",
        "                    ],\n",
        "                }\n",
        "            ],\n",
        "        )\n",
        "\n",
        "        # Parse the response and append to extraction_results\n",
        "        extracted_data = json.loads(generation.choices[0].message.content)\n",
        "        extraction_results.append(extracted_data)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error invoking deployment for an image: {e}\")\n",
        "\n",
        "# At this point, extraction_results is ready for the next deployment\n"
      ],
      "metadata": {
        "id": "ndcb3Ll7wj8F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a34352e2-fd32-4ee3-98bd-766d979d2e5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error invoking deployment for an image: Expecting value: line 1 column 1 (char 0)\n",
            "Error invoking deployment for an image: Expecting value: line 1 column 1 (char 0)\n",
            "Error invoking deployment for an image: Expecting value: line 1 column 1 (char 0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Financial Analyst Categorizing and Summarizing the data\n",
        "---\n",
        "\n",
        "The second deployment summarizes the extracted financial data, providing a high-level overview of expenses. It highlights total spending, detects unusual charges, and identifies potential cost-saving opportunities, ensuring a clear and concise financial snapshot."
      ],
      "metadata": {
        "id": "x5Y5qmUqV5Ha"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Prompt**\n",
        "\n",
        "This prompt guides the model to act as an experienced financial analyst, focusing on expense management and receipt analysis. It goes beyond simple data extraction by requesting a detailed expense breakdown, identification of unusual charges, and an analysis of spending patterns. Additionally, it includes actionable insights, such as cost-saving recommendations, tax deduction opportunities, and compliance checks. By summarizing totals for each category and flagging receipts that may need further review, this prompt ensures a comprehensive financial assessment, making it useful for both accounting and tax reporting."
      ],
      "metadata": {
        "id": "xnPDizNAbvj6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "try:\n",
        "    # Convert the combined JSON list to a JSON string\n",
        "    combined_json_string = json.dumps(extraction_results)\n",
        "\n",
        "    # Invoke the financial summarization deployment\n",
        "    summarization = client.deployments.invoke(\n",
        "        key=\"financial-analyst-summarizer\",\n",
        "        context={\n",
        "            \"environments\": []\n",
        "        },\n",
        "        inputs={\n",
        "            \"json\": combined_json_string\n",
        "        },\n",
        "        metadata={\n",
        "            \"custom-field-name\": \"custom-metadata-value\"\n",
        "        }\n",
        "    )\n",
        "\n",
        "    # Print the summarization result\n",
        "    print(summarization.choices[0].message.content)\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error invoking financial summarization deployment: {e}\")"
      ],
      "metadata": {
        "id": "CUZOqVOlYiAt",
        "outputId": "5988ebea-412b-4d9c-a405-66e2e4446208",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error invoking financial summarization deployment: name 'extraction_results' is not defined\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**What’s Next?**  \n",
        "With this workflow, you now have a concrete example of how to configure and chain multiple deployments in Orq, transforming unstructured data into structured insights. Beyond receipt processing, this approach can be applied to a wide range of workflows, such as document parsing, customer feedback analysis, or automated compliance checks.\n",
        "\n",
        "- **Scale and Adapt:** Apply the same principles to process different data types, from text documents to audio transcripts or sensor data.\n",
        "- **Optimize with Evaluations:** Run targeted evaluations at key steps to ensure accuracy, detect anomalies, and refine model performance.\n",
        "- **Automate Decision-Making:** Use chained deployments to create intelligent workflows that extract, analyze, and act on data with minimal manual intervention.\n",
        "\n",
        "By leveraging Orq’s flexible deployment framework, businesses can design custom AI-driven pipelines to streamline operations, enhance decision-making, and unlock new efficiencies across various domains."
      ],
      "metadata": {
        "id": "JbDGxmEvy9Vg"
      }
    }
  ]
}